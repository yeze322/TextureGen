{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import caffe\n",
    "base_dir = os.getcwd()\n",
    "sys.path.append(base_dir)\n",
    "from DeepImageSynthesis import *\n",
    "VGGweights = os.path.join(base_dir, 'Models/VGG_normalised.caffemodel')\n",
    "VGGmodel = os.path.join(base_dir, 'Models/VGG_ave_pool_deploy.prototxt')\n",
    "imagenet_mean = numpy.array([ 0.40760392,  0.45795686,  0.48501961]) #mean for color channels (bgr)\n",
    "im_dir = os.path.join(base_dir, 'Images/')\n",
    "gpu = 0\n",
    "caffe.set_mode_gpu() #for cpu mode do 'caffe.set_mode_cpu()'\n",
    "caffe.set_device(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_image() takes exactly 2 arguments (6 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0146f43d351d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m [source_img, net] = load_image(im_dir + source_img_name, im_size, \n\u001b[0;32m      7\u001b[0m                             \u001b[0mVGGmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVGGweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimagenet_mean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                             show_img=True)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mim_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0minitpic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Images/songti/129.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: load_image() takes exactly 2 arguments (6 given)"
     ]
    }
   ],
   "source": [
    "#load source image\n",
    "im_dir += 'lishu/'\n",
    "source_img_name = glob.glob1(im_dir, '12.jpg')[0]\n",
    "source_img_org = caffe.io.load_image(im_dir + source_img_name)\n",
    "im_size = 200.\n",
    "[source_img, net] = load_image(im_dir + source_img_name, im_size, \n",
    "                            VGGmodel, VGGweights, imagenet_mean, \n",
    "                            show_img=True)\n",
    "im_size = asarray(source_img.shape[-2:])\n",
    "initpic = caffe.io.load_image('./Images/songti/129.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#l-bfgs parameters optimisation\n",
    "maxiter = 200\n",
    "m = 10\n",
    "\n",
    "#define layers to include in the texture model and weights w_l\n",
    "tex_layers = ['pool4', 'pool3', 'pool2', 'pool1', 'conv1_1']\n",
    "tex_weights = [1e9,1e9,1e9,1e9,1e9]\n",
    "\n",
    "#pass image through the network and save the constraints on each layer\n",
    "constraints = OrderedDict()\n",
    "net.forward(data = source_img)\n",
    "for l,layer in enumerate(tex_layers):\n",
    "    constraints[layer] = constraint([LossFunctions.gram_mse_loss],\n",
    "                                    [{'target_gram_matrix': gram_matrix(net.blobs[layer].data),\n",
    "                                      'weight': tex_weights[l]}])\n",
    "#get optimisation bounds\n",
    "bounds = get_bounds([source_img],im_size)\n",
    "\n",
    "#generate new texture\n",
    "result = ImageSyn(net, constraints, bounds=bounds,\n",
    "                  callback=lambda x: show_progress(x,net), \n",
    "                  minimize_options={'maxiter': maxiter,\n",
    "                                    'maxcor': m,\n",
    "                                    'ftol': 0, 'gtol': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import caffe\n",
    "from DeepImageSynthesis import *\n",
    "\n",
    "#set caculation mode and choose gpu device\n",
    "gpu = 0\n",
    "caffe.set_mode_gpu() #for cpu mode do 'caffe.set_mode_cpu()'\n",
    "caffe.set_device(gpu)\n",
    "\n",
    "#Path parameters\n",
    "VGGweights = '/home/yeze/Documents/gitxivprojects/DeepTextures/Models/VGG_normalised.caffemodel'\n",
    "VGGmodel = '/home/yeze/Documents/gitxivprojects/DeepTextures/Models/VGG_ave_pool_deploy.prototxt'\n",
    "source_img_name = '/home/yeze/Documents/gitxivprojects/DeepTextures/Images/lishu/12.jpg'\n",
    "imagenet_mean = numpy.array([ 0.40760392,  0.45795686,  0.48501961]) #mean for color channels (bgr)\n",
    "\n",
    "#load source image\n",
    "im_size = 200.\n",
    "source_img, net = load_image(source_img_name, im_size, \n",
    "                            VGGmodel, VGGweights, imagenet_mean, \n",
    "                            show_img=True)\n",
    "im_size = asarray(source_img.shape[-2:])\n",
    "initpic = caffe.io.load_image('./Images/songti/129.jpg')\n",
    "\n",
    "#l-bfgs parameters optimisation\n",
    "maxiter = 2\n",
    "m = 10\n",
    "\n",
    "#define layers to include in the texture model and weights w_l\n",
    "tex_layers = ['pool4', 'pool3', 'pool2', 'pool1', 'conv1_1']\n",
    "tex_weights = [1e9,1e9,1e9,1e9,1e9]\n",
    "\n",
    "#pass image through the network and save the constraints on each layer\n",
    "constraints = OrderedDict()\n",
    "net.forward(data = source_img)\n",
    "for l,layer in enumerate(tex_layers):\n",
    "    constraints[layer] = constraint([LossFunctions.gram_mse_loss],\n",
    "                                    [{'target_gram_matrix': gram_matrix(net.blobs[layer].data),\n",
    "                                      'weight': tex_weights[l]}])\n",
    "#get optimisation bounds\n",
    "bounds = get_bounds([source_img],im_size)\n",
    "\n",
    "#generate new texture\n",
    "result = ImageSyn(net, constraints, bounds=bounds,\n",
    "                  callback=lambda x: show_progress(x,net), \n",
    "                  minimize_options={'maxiter': maxiter,\n",
    "                                    'maxcor': m,\n",
    "                                    'ftol': 0, 'gtol': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
